import os
import sys
import json
import torch
import torch.nn as nn
from torchvision import models, transforms
from torch.utils.data import Dataset, DataLoader, random_split
from PIL import Image
from tqdm.auto import tqdm
from collections import defaultdict
from sklearn.metrics import f1_score
import pandas as pd
from datetime import datetime
import glob

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(os.path.abspath(os.path.join(__file__, "..", "..")))

# ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
from config.config import CLASS_MAPPINGS

# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ êµ¬ì¡° ê²½ë¡œ ê³„ì‚°
current_dir = os.path.dirname(__file__)  # AI í´ë”
algorithm_dir = os.path.dirname(current_dir)  # Algorithm í´ë”
project_root = os.path.dirname(algorithm_dir)  # í”„ë¡œì íŠ¸ ë£¨íŠ¸

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
IMAGE_DIR = os.path.join(project_root, "backend", "DATA", "images")
LABEL_DIR = os.path.join(project_root, "backend", "DATA", "labels")
BATCH_SIZE = 16
NUM_WORKERS = 0

# ëª¨ë¸ í´ë” ê²½ë¡œ ì„¤ì •
MODELS_DIR = os.path.join(project_root, "AI", "ResNet50_summary", "EXP")
RESULTS_DIR = os.path.join(project_root, "AI", "ResNet50_summary", "RESULTS")

# âœ¨ 4ê°œ ì£¼ìš” ì¹´í…Œê³ ë¦¬ ì •ì˜
SELECTED_CATEGORIES = ["ì•„ìš°í„°", "ìƒì˜", "í•˜ì˜", "ì›í”¼ìŠ¤"]

# âœ¨ 21ê°œ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ â†’ 4ê°œ ëŒ€ë¶„ë¥˜ ë§¤í•‘
CATEGORY_MAPPING = {
    # ìƒì˜
    "íƒ‘": "ìƒì˜",
    "ë¸”ë¼ìš°ìŠ¤": "ìƒì˜",
    "í‹°ì…”ì¸ ": "ìƒì˜",
    "ë‹ˆíŠ¸ì›¨ì–´": "ìƒì˜",
    "ì…”ì¸ ": "ìƒì˜",
    "ë¸Œë¼íƒ‘": "ìƒì˜",
    "í›„ë“œí‹°": "ìƒì˜",
    # í•˜ì˜
    "ì²­ë°”ì§€": "í•˜ì˜",
    "íŒ¬ì¸ ": "í•˜ì˜",
    "ìŠ¤ì»¤íŠ¸": "í•˜ì˜",
    "ë ˆê¹…ìŠ¤": "í•˜ì˜",
    "ì¡°ê±°íŒ¬ì¸ ": "í•˜ì˜",
    # ì•„ìš°í„°
    "ì½”íŠ¸": "ì•„ìš°í„°",
    "ì¬í‚·": "ì•„ìš°í„°",
    "ì í¼": "ì•„ìš°í„°",
    "íŒ¨ë”©": "ì•„ìš°í„°",
    "ë² ìŠ¤íŠ¸": "ì•„ìš°í„°",
    "ê°€ë””ê±´": "ì•„ìš°í„°",
    "ì§šì—…": "ì•„ìš°í„°",
    # ì›í”¼ìŠ¤
    "ë“œë ˆìŠ¤": "ì›í”¼ìŠ¤",
    "ì í”„ìˆ˜íŠ¸": "ì›í”¼ìŠ¤",
}

# í•œê¸€â†’ì˜ì–´ í‚¤ ë§µí•‘
KOR_TO_ENG = {
    "ì¹´í…Œê³ ë¦¬": "category",
    "ìƒ‰ìƒ": "color",
    "ì†Œë§¤ê¸°ì¥": "sleeve_length",
    "ê¸°ì¥": "sleeve_length",
    "ì˜·ê¹ƒ": "collar",
    "ë„¥ë¼ì¸": "neckline",
    "í•": "fit",
    "í”„ë¦°íŠ¸": "print",
    "ì†Œì¬": "material",
    "ë””í…Œì¼": "detail",
    "ìŠ¤íƒ€ì¼": "style",
}


class MultiTaskResNet50(nn.Module):
    def __init__(self, mappings):
        super().__init__()
        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
        backbone.fc = nn.Identity()
        self.backbone = backbone
        self.heads = nn.ModuleDict(
            {k: nn.Linear(2048, len(v)) for k, v in mappings.items() if k != "category"}
        )

    def forward(self, x):
        feat = self.backbone(x)
        return {k: head(feat) for k, head in self.heads.items()}


class FashionAttributePredictor:
    def __init__(self, model_path, device=None, top_k=3):
        self.device = device or DEVICE
        self.top_k = top_k
        self.model_path = model_path

        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model not found: {model_path}")

        self.model = MultiTaskResNet50(CLASS_MAPPINGS).to(self.device)
        self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        self.model.eval()

        self.transform = transforms.Compose(
            [
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
            ]
        )

    def predict_image(self, image_path):
        img = Image.open(image_path).convert("RGB")
        x = self.transform(img).unsqueeze(0).to(self.device)
        with torch.no_grad():
            outs = self.model(x)
        results = {}
        for attr, logits in outs.items():
            probs = torch.softmax(logits, dim=1)
            top_p, top_i = torch.topk(probs, min(self.top_k, probs.size(1)), dim=1)
            results[attr] = [
                {
                    "class_name": CLASS_MAPPINGS[attr][idx.item()],
                    "probability": float(top_p[0, i].item()),
                }
                for i, idx in enumerate(top_i[0])
            ]
        return results


class FashionValDataset(Dataset):
    def __init__(self, img_dir, lbl_dir, mappings, transform=None):
        self.img_dir = img_dir
        self.lbl_dir = lbl_dir
        self.mappings = mappings
        self.transform = transform
        self.files = [f for f in os.listdir(img_dir) if f.lower().endswith(".jpg")]

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        fn = self.files[idx]
        img = Image.open(os.path.join(self.img_dir, fn)).convert("RGB")
        if self.transform:
            img = self.transform(img)
        labels = {k: -1 for k in self.mappings}
        jp = os.path.join(self.lbl_dir, fn.rsplit(".", 1)[0] + ".json")
        if os.path.exists(jp):
            data = json.load(open(jp, encoding="utf-8"))
            lab = (
                data.get("ë°ì´í„°ì…‹ ì •ë³´", {})
                .get("ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª…", {})
                .get("ë¼ë²¨ë§", {})
            )
            for part in lab.values():
                for item in part:
                    if not isinstance(item, dict):
                        continue
                    for kor, v in item.items():
                        eng = KOR_TO_ENG.get(kor)
                        if eng is None or v in (None, "", []):
                            continue
                        vals = v if isinstance(v, list) else [v]
                        for vv in vals:
                            if vv in self.mappings[eng]:
                                labels[eng] = self.mappings[eng].index(vv)
                                break
                        if labels[eng] != -1:
                            continue
        return img, labels


def collate_fn(batch):
    imgs = torch.stack([b[0] for b in batch], dim=0)
    lbls = {
        k: torch.tensor([b[1][k] for b in batch], dtype=torch.long) for k in batch[0][1]
    }
    return imgs, lbls


def count_labels_per_category_attribute(
    loader, selected_categories, class_mappings, category_mapping
):
    """ê° ì¹´í…Œê³ ë¦¬(ëŒ€ë¶„ë¥˜), ì†ì„±ë³„ ì‹¤ì œ ë¼ë²¨ ê°œìˆ˜ ì¹´ìš´íŠ¸"""
    label_counts = defaultdict(lambda: defaultdict(int))

    for imgs, labels in tqdm(loader, desc="Counting labels", leave=False):
        cats = labels["category"].tolist()
        batch_size = len(cats)

        for i in range(batch_size):
            c = cats[i]
            if c < 0:
                continue
            cn = class_mappings["category"][c]
            main_cat = category_mapping.get(cn)
            if main_cat is None or main_cat not in selected_categories:
                continue

            for attr in labels:
                if attr == "category":
                    continue
                label_val = labels[attr][i].item()
                if label_val >= 0:  # ìœ íš¨í•œ ë¼ë²¨ë§Œ ì¹´ìš´íŠ¸
                    label_counts[main_cat][attr] += 1

    return label_counts


def validate(model, loader, model_name, selected_categories=None):
    """ë‹¨ì¼ ëª¨ë¸ ê²€ì¦ (íŠ¹ì • ì¹´í…Œê³ ë¦¬ë§Œ ì„±ëŠ¥ê³„ì‚°) + ë ˆì´ë¸” ê°œìˆ˜ í¬í•¨"""
    if selected_categories is None:
        selected_categories = SELECTED_CATEGORIES

    model.eval()
    cat_t = defaultdict(lambda: defaultdict(list))
    cat_p = defaultdict(lambda: defaultdict(list))

    # âœ¨ ë¨¼ì € ë ˆì´ë¸” ê°œìˆ˜ ì¹´ìš´íŠ¸
    print(f"ğŸ“Š ë ˆì´ë¸” ê°œìˆ˜ ê³„ì‚° ì¤‘...")
    label_counts = count_labels_per_category_attribute(
        loader, selected_categories, CLASS_MAPPINGS, CATEGORY_MAPPING
    )

    pbar = tqdm(
        loader,
        desc=f"Validating {model_name} (4ê°œ ì¹´í…Œê³ ë¦¬)",
        bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]",
    )

    with torch.no_grad():
        for imgs, labels in pbar:
            imgs = imgs.to(DEVICE)
            outs = model(imgs)
            cats = labels["category"].tolist()

            for i, c in enumerate(cats):
                if c < 0:
                    continue
                cn = CLASS_MAPPINGS["category"][c]

                # ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë¥¼ ëŒ€ë¶„ë¥˜ë¡œ ë§¤í•‘
                main_category = CATEGORY_MAPPING.get(cn)
                if main_category is None or main_category not in selected_categories:
                    continue

                for attr, out in outs.items():
                    tl = labels[attr][i].item()
                    if tl < 0:
                        continue
                    pr = out[i].argmax().item()
                    cat_t[main_category][attr].append(tl)
                    cat_p[main_category][attr].append(pr)

    # F1 ìŠ¤ì½”ì–´ ê³„ì‚° + ë ˆì´ë¸” ê°œìˆ˜ í¬í•¨
    results = {}
    for cn, attrs in cat_t.items():
        fs = {}
        for attr, tr in attrs.items():
            pr = cat_p[cn][attr]
            f1 = f1_score(tr, pr, average="macro", zero_division=0) if tr else 0.0
            total_labels = label_counts[cn][attr]  # âœ¨ ì´ ë ˆì´ë¸” ê°œìˆ˜
            fs[attr] = {"f1_score": f1, "total_labels": total_labels}
        results[cn] = fs

    return results


def validate_multiple_models(models_dir, results_dir):
    """ì—¬ëŸ¬ ëª¨ë¸ ê²€ì¦ ë° ê²°ê³¼ ì €ì¥ (4ê°œ ì¹´í…Œê³ ë¦¬ë§Œ) + ë ˆì´ë¸” ê°œìˆ˜ í¬í•¨"""

    os.makedirs(results_dir, exist_ok=True)
    model_files = glob.glob(os.path.join(models_dir, "*.pth"))

    if not model_files:
        print(f"No .pth files found in {models_dir}")
        return

    print(f"Found {len(model_files)} model files")
    print(f"ê²€ì¦ ëŒ€ìƒ ì¹´í…Œê³ ë¦¬: {', '.join(SELECTED_CATEGORIES)}")

    # ë°ì´í„°ì…‹ ì¤€ë¹„
    transform = transforms.Compose(
        [
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ]
    )

    ds = FashionValDataset(IMAGE_DIR, LABEL_DIR, CLASS_MAPPINGS, transform)
    _, val_ds = random_split(ds, [int(len(ds) * 0.8), len(ds) - int(len(ds) * 0.8)])
    loader = DataLoader(
        val_ds,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=NUM_WORKERS,
        collate_fn=collate_fn,
    )

    all_results = {}
    detailed_results = []

    # ê° ëª¨ë¸ì— ëŒ€í•´ ê²€ì¦ ìˆ˜í–‰
    for model_file in model_files:
        model_name = os.path.basename(model_file).replace(".pth", "")
        print(f"\n{'='*50}")
        print(f"Validating model: {model_name}")
        print(f"{'='*50}")

        try:
            predictor = FashionAttributePredictor(model_file, device=DEVICE)
            stats = validate(predictor.model, loader, model_name, SELECTED_CATEGORIES)
            all_results[model_name] = stats

            # âœ¨ ìƒì„¸ ê²°ê³¼ ìˆ˜ì§‘ (ë ˆì´ë¸” ê°œìˆ˜ í¬í•¨)
            for category, metrics in stats.items():
                for attribute, metric_data in metrics.items():
                    detailed_results.append(
                        {
                            "model_name": model_name,
                            "category": category,
                            "attribute": attribute,
                            "f1_score": metric_data["f1_score"],
                            "total_labels": metric_data["total_labels"],
                        }
                    )

            # âœ¨ ê°œë³„ ëª¨ë¸ ê²°ê³¼ ì¶œë ¥ (ë ˆì´ë¸” ê°œìˆ˜ í¬í•¨)
            print(f"\nResults for {model_name} (4ê°œ ì£¼ìš” ì¹´í…Œê³ ë¦¬):")
            for cat, metrics in stats.items():
                print(f"\n--- Category: {cat} ---")
                df_data = {
                    "F1 Score": [metrics[attr]["f1_score"] for attr in metrics],
                    "Total Labels": [metrics[attr]["total_labels"] for attr in metrics],
                }
                df = pd.DataFrame(df_data, index=list(metrics.keys()))
                df.index.name = "Attribute"
                print(df.to_string(float_format="%.4f"))

        except Exception as e:
            print(f"Error validating model {model_name}: {str(e)}")
            continue

    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    if detailed_results:
        # âœ¨ 1. ìƒì„¸ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥ (ë ˆì´ë¸” ê°œìˆ˜ í¬í•¨)
        detailed_df = pd.DataFrame(detailed_results)
        detailed_csv_path = os.path.join(
            results_dir,
            f"detailed_validation_results_4categories_with_counts_{timestamp}.csv",
        )
        detailed_df.to_csv(detailed_csv_path, index=False, encoding="utf-8-sig")
        print(f"\nìƒì„¸ ê²°ê³¼ ì €ì¥ë¨: {detailed_csv_path}")

        # âœ¨ 2. F1 ìŠ¤ì½”ì–´ë§Œìœ¼ë¡œ í”¼ë²— í…Œì´ë¸” ìƒì„±
        summary_df = detailed_df.pivot_table(
            index=["category", "attribute"],
            columns="model_name",
            values="f1_score",
            fill_value=0,
        )
        summary_csv_path = os.path.join(
            results_dir,
            f"summary_validation_results_4categories_with_counts_{timestamp}.csv",
        )
        summary_df.to_csv(summary_csv_path, encoding="utf-8-sig")
        print(f"ìš”ì•½ ê²°ê³¼ ì €ì¥ë¨: {summary_csv_path}")

        # âœ¨ 3. ë ˆì´ë¸” ê°œìˆ˜ í”¼ë²— í…Œì´ë¸” ë³„ë„ ì €ì¥
        labels_df = detailed_df.pivot_table(
            index=["category", "attribute"],
            columns="model_name",
            values="total_labels",
            fill_value=0,
            aggfunc="first",  # ëª¨ë“  ëª¨ë¸ì—ì„œ ë ˆì´ë¸” ê°œìˆ˜ëŠ” ë™ì¼í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
        )
        labels_csv_path = os.path.join(
            results_dir, f"label_counts_by_category_attribute_{timestamp}.csv"
        )
        labels_df.to_csv(labels_csv_path, encoding="utf-8-sig")
        print(f"ë ˆì´ë¸” ê°œìˆ˜ ì €ì¥ë¨: {labels_csv_path}")

        # 4. ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥ ê³„ì‚°
        model_avg_df = (
            detailed_df.groupby("model_name")["f1_score"]
            .agg(["mean", "std", "count"])
            .round(4)
        )
        model_avg_df.columns = ["Mean_F1", "Std_F1", "Num_Attributes"]
        model_avg_path = os.path.join(
            results_dir,
            f"model_average_performance_4categories_with_counts_{timestamp}.csv",
        )
        model_avg_df.to_csv(model_avg_path, encoding="utf-8-sig")
        print(f"ëª¨ë¸ í‰ê·  ì„±ëŠ¥ ì €ì¥ë¨: {model_avg_path}")

    # 5. ì „ì²´ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥ (ë ˆì´ë¸” ê°œìˆ˜ í¬í•¨)
    json_path = os.path.join(
        results_dir, f"full_validation_results_4categories_with_counts_{timestamp}.json"
    )
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    print(f"ì „ì²´ ê²°ê³¼ JSON ì €ì¥ë¨: {json_path}")

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°
    if detailed_results:
        best_model = detailed_df.groupby("model_name")["f1_score"].mean().idxmax()
        best_score = detailed_df.groupby("model_name")["f1_score"].mean().max()
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model} (í‰ê·  F1: {best_score:.4f})")

    return all_results


def create_comparison_report(results_dir, results_data):
    """ëª¨ë¸ ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„± (4ê°œ ì¹´í…Œê³ ë¦¬) + ë ˆì´ë¸” ê°œìˆ˜ í¬í•¨"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ëª¨ë¸ë³„ ì „ì²´ í‰ê·  ì„±ëŠ¥ + ì´ ë ˆì´ë¸” ê°œìˆ˜
    model_performance = {}
    for model_name, categories in results_data.items():
        all_scores = []
        total_labels = 0
        for cat_metrics in categories.values():
            for metric_data in cat_metrics.values():
                all_scores.append(metric_data["f1_score"])
                total_labels += metric_data["total_labels"]

        if all_scores:
            model_performance[model_name] = {
                "average_f1": sum(all_scores) / len(all_scores),
                "num_metrics": len(all_scores),
                "total_labels": total_labels,
            }

    # ë¦¬í¬íŠ¸ ìƒì„±
    report_path = os.path.join(
        results_dir, f"model_comparison_report_4categories_with_counts_{timestamp}.txt"
    )
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("=" * 70 + "\n")
        f.write("íŒ¨ì…˜ ì†ì„± ì˜ˆì¸¡ ëª¨ë¸ ê²€ì¦ ë¦¬í¬íŠ¸ (4ê°œ ì£¼ìš” ì¹´í…Œê³ ë¦¬ + ë ˆì´ë¸” ê°œìˆ˜)\n")
        f.write("=" * 70 + "\n")
        f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ê²€ì¦ ëª¨ë¸ ìˆ˜: {len(results_data)}\n")
        f.write(f"ê²€ì¦ ì¹´í…Œê³ ë¦¬: {', '.join(SELECTED_CATEGORIES)}\n\n")

        f.write("ëª¨ë¸ë³„ ì „ì²´ í‰ê·  ì„±ëŠ¥:\n")
        f.write("-" * 50 + "\n")

        sorted_models = sorted(
            model_performance.items(), key=lambda x: x[1]["average_f1"], reverse=True
        )

        for i, (model_name, perf) in enumerate(sorted_models, 1):
            f.write(
                f"{i}. {model_name}: {perf['average_f1']:.4f} "
                f"(ì´ {perf['num_metrics']}ê°œ ì§€í‘œ, {perf['total_labels']}ê°œ ë ˆì´ë¸”)\n"
            )

    print(f"ë¹„êµ ë¦¬í¬íŠ¸ ì €ì¥ë¨: {report_path}")


if __name__ == "__main__":
    # ê¸°ë³¸ê°’ì„ ë™ì  ê²½ë¡œë¡œ ì„¤ì •
    default_models_dir = os.path.join(project_root, "AI", "ResNet50_summary", "EXP")
    default_results_dir = os.path.join(project_root, "AI", "ResNet50_summary", "RESULTS")
    
    MODELS_DIR = input("ëª¨ë¸ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not MODELS_DIR:
        MODELS_DIR = default_models_dir

    RESULTS_DIR = input("ê²°ê³¼ ì €ì¥ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì—”í„°ì‹œ ê¸°ë³¸ê°’): ").strip()
    if not RESULTS_DIR:
        RESULTS_DIR = default_results_dir

    print(f"ëª¨ë¸ í´ë”: {MODELS_DIR}")
    print(f"ê²°ê³¼ ì €ì¥: {RESULTS_DIR}")
    print(f"ê²€ì¦ ëŒ€ìƒ: {', '.join(SELECTED_CATEGORIES)}")

    results = validate_multiple_models(MODELS_DIR, RESULTS_DIR)

    if results:
        create_comparison_report(RESULTS_DIR, results)
        print(f"\nâœ… ê²€ì¦ ì™„ë£Œ! ì´ {len(results)}ê°œ ëª¨ë¸ì´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤ì´ {RESULTS_DIR}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ¯ ê²€ì¦ëœ ì¹´í…Œê³ ë¦¬: {', '.join(SELECTED_CATEGORIES)}")
    else:
        print("âŒ ê²€ì¦í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
